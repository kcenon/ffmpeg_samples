/**
 * Audio Spectrum Visualizer
 *
 * This sample demonstrates how to create audio spectrum visualization videos
 * using modern C++20 and FFmpeg libraries.
 */

#include "ffmpeg_wrappers.hpp"

#include <iostream>
#include <format>
#include <filesystem>
#include <string_view>
#include <unordered_map>

namespace fs = std::filesystem;

namespace {

enum class VisualizationMode {
    SPECTRUM,
    WAVEFORM,
    SHOWCQT,
    SHOWFREQS,
    SHOWWAVES
};

VisualizationMode parse_mode(std::string_view mode_str) {
    static const std::unordered_map<std::string_view, VisualizationMode> modes = {
        {"spectrum", VisualizationMode::SPECTRUM},
        {"waveform", VisualizationMode::WAVEFORM},
        {"showcqt", VisualizationMode::SHOWCQT},
        {"showfreqs", VisualizationMode::SHOWFREQS},
        {"showwaves", VisualizationMode::SHOWWAVES}
    };

    const auto it = modes.find(mode_str);
    if (it == modes.end()) {
        throw std::invalid_argument(std::format("Invalid mode: {}", mode_str));
    }
    return it->second;
}

std::string get_filter_description(VisualizationMode mode, int width, int height) {
    switch (mode) {
        case VisualizationMode::SPECTRUM:
            return std::format(
                "showspectrum=s={}x{}:mode=combined:color=channel:scale=cbrt",
                width, height
            );
        case VisualizationMode::WAVEFORM:
            return std::format(
                "showwaves=s={}x{}:mode=cline:colors=red|green|blue|yellow",
                width, height
            );
        case VisualizationMode::SHOWCQT:
            return std::format(
                "showcqt=s={}x{}:fps=30:sono_h=0:bar_h=16:axis_h=0:font=''",
                width, height
            );
        case VisualizationMode::SHOWFREQS:
            return std::format(
                "showfreqs=s={}x{}:mode=bar:cmode=combined:minamp=1e-6",
                width, height
            );
        case VisualizationMode::SHOWWAVES:
            return std::format(
                "showwaves=s={}x{}:mode=p2p:colors=0xff0000|0x00ff00|0x0000ff",
                width, height
            );
        default:
            return std::format("showspectrum=s={}x{}", width, height);
    }
}

class AudioSpectrumVisualizer {
public:
    AudioSpectrumVisualizer(std::string_view input_audio, const fs::path& output_video,
                          VisualizationMode mode, int width, int height, int fps)
        : input_audio_(input_audio)
        , output_video_(output_video)
        , mode_(mode)
        , width_(width)
        , height_(height)
        , fps_(fps)
        , format_ctx_(ffmpeg::open_input_format(input_audio.data()))
        , packet_(ffmpeg::create_packet()) {

        initialize();
    }

    void generate() {
        std::cout << "Audio Spectrum Visualization\n";
        std::cout << "============================\n\n";
        std::cout << std::format("Input audio: {}\n", input_audio_);
        std::cout << std::format("Output video: {}\n", output_video_.string());
        std::cout << std::format("Resolution: {}x{}\n", width_, height_);
        std::cout << std::format("FPS: {}\n", fps_);
        std::cout << std::format("Sample rate: {} Hz\n\n", codec_ctx_->sample_rate);

        // Create output context
        AVFormatContext* output_ctx_raw = nullptr;
        ffmpeg::check_error(
            avformat_alloc_output_context2(&output_ctx_raw, nullptr, nullptr,
                                          output_video_.string().c_str()),
            "allocate output context"
        );
        auto output_ctx = ffmpeg::FormatContextPtr(output_ctx_raw);

        // Create video stream
        auto* out_stream = avformat_new_stream(output_ctx.get(), nullptr);
        if (!out_stream) {
            throw ffmpeg::FFmpegError("Failed to create output stream");
        }

        // Setup encoder
        const auto* encoder = avcodec_find_encoder(AV_CODEC_ID_H264);
        if (!encoder) {
            throw ffmpeg::FFmpegError("H.264 encoder not found");
        }

        encoder_ctx_ = ffmpeg::create_codec_context(encoder);
        encoder_ctx_->width = width_;
        encoder_ctx_->height = height_;
        encoder_ctx_->pix_fmt = AV_PIX_FMT_YUV420P;
        encoder_ctx_->time_base = AVRational{1, fps_};
        encoder_ctx_->framerate = AVRational{fps_, 1};
        encoder_ctx_->bit_rate = 2000000;

        if (output_ctx->oformat->flags & AVFMT_GLOBALHEADER) {
            encoder_ctx_->flags |= AV_CODEC_FLAG_GLOBAL_HEADER;
        }

        ffmpeg::check_error(
            avcodec_open2(encoder_ctx_.get(), encoder, nullptr),
            "open encoder"
        );

        ffmpeg::check_error(
            avcodec_parameters_from_context(out_stream->codecpar, encoder_ctx_.get()),
            "copy encoder parameters"
        );

        out_stream->time_base = encoder_ctx_->time_base;

        // Open output file
        if (!(output_ctx->oformat->flags & AVFMT_NOFILE)) {
            ffmpeg::check_error(
                avio_open(&output_ctx->pb, output_video_.string().c_str(), AVIO_FLAG_WRITE),
                "open output file"
            );
        }

        // Write header
        ffmpeg::check_error(
            avformat_write_header(output_ctx.get(), nullptr),
            "write header"
        );

        // Process audio and generate visualization
        std::cout << "Generating visualization...\n";

        int frame_count = 0;
        auto video_frame = ffmpeg::create_frame();

        while (av_read_frame(format_ctx_.get(), packet_.get()) >= 0) {
            ffmpeg::ScopedPacketUnref packet_guard(packet_.get());

            if (packet_->stream_index != audio_stream_index_) {
                continue;
            }

            const auto ret = avcodec_send_packet(codec_ctx_.get(), packet_.get());
            if (ret < 0) {
                continue;
            }

            while (true) {
                auto audio_frame = ffmpeg::create_frame();
                const auto recv_ret = avcodec_receive_frame(codec_ctx_.get(), audio_frame.get());

                if (recv_ret == AVERROR(EAGAIN) || recv_ret == AVERROR_EOF) {
                    break;
                }

                if (recv_ret < 0) {
                    break;
                }

                ffmpeg::ScopedFrameUnref audio_guard(audio_frame.get());

                // Push audio frame through filter
                ffmpeg::check_error(
                    av_buffersrc_add_frame_flags(buffersrc_ctx_, audio_frame.get(),
                                               AV_BUFFERSRC_FLAG_KEEP_REF),
                    "feed audio frame to filter"
                );

                // Get video frames from filter
                while (true) {
                    const auto filter_ret = av_buffersink_get_frame(buffersink_ctx_,
                                                                   video_frame.get());

                    if (filter_ret == AVERROR(EAGAIN) || filter_ret == AVERROR_EOF) {
                        break;
                    }

                    if (filter_ret < 0) {
                        break;
                    }

                    ffmpeg::ScopedFrameUnref video_guard(video_frame.get());

                    // Set correct PTS
                    video_frame->pts = frame_count++;

                    // Encode and write frame
                    encode_write_frame(output_ctx.get(), out_stream, video_frame.get());

                    if (frame_count % 30 == 0) {
                        const auto seconds = frame_count / static_cast<double>(fps_);
                        std::cout << std::format("Generated {:.2f} seconds\r", seconds) << std::flush;
                    }
                }
            }
        }

        // Flush filter
        av_buffersrc_add_frame_flags(buffersrc_ctx_, nullptr, 0);

        while (true) {
            const auto filter_ret = av_buffersink_get_frame(buffersink_ctx_, video_frame.get());

            if (filter_ret == AVERROR(EAGAIN) || filter_ret == AVERROR_EOF) {
                break;
            }

            if (filter_ret < 0) {
                break;
            }

            ffmpeg::ScopedFrameUnref video_guard(video_frame.get());

            video_frame->pts = frame_count++;
            encode_write_frame(output_ctx.get(), out_stream, video_frame.get());
        }

        // Flush encoder
        flush_encoder(output_ctx.get(), out_stream);

        // Write trailer
        ffmpeg::check_error(
            av_write_trailer(output_ctx.get()),
            "write trailer"
        );

        const auto duration = frame_count / static_cast<double>(fps_);
        std::cout << std::format("\n\nTotal frames: {}\n", frame_count);
        std::cout << std::format("Duration: {:.2f} seconds\n", duration);
        std::cout << std::format("âœ“ Visualization generated successfully\n");
        std::cout << std::format("Output file: {}\n", output_video_.string());
    }

private:
    void initialize() {
        // Find audio stream
        const auto stream_idx = ffmpeg::find_stream_index(format_ctx_.get(), AVMEDIA_TYPE_AUDIO);
        if (!stream_idx) {
            throw ffmpeg::FFmpegError("No audio stream found");
        }
        audio_stream_index_ = *stream_idx;

        // Setup decoder
        const auto* codecpar = format_ctx_->streams[audio_stream_index_]->codecpar;
        const auto* decoder = avcodec_find_decoder(codecpar->codec_id);
        if (!decoder) {
            throw ffmpeg::FFmpegError("Audio decoder not found");
        }

        codec_ctx_ = ffmpeg::create_codec_context(decoder);
        ffmpeg::check_error(
            avcodec_parameters_to_context(codec_ctx_.get(), codecpar),
            "copy decoder parameters"
        );
        ffmpeg::check_error(
            avcodec_open2(codec_ctx_.get(), decoder, nullptr),
            "open decoder"
        );

        // Initialize visualization filter
        initialize_filter();
    }

    void initialize_filter() {
        const auto* abuffersrc = avfilter_get_by_name("abuffer");
        const auto* buffersink = avfilter_get_by_name("buffersink");

        filter_graph_.reset(avfilter_graph_alloc());
        if (!filter_graph_) {
            throw ffmpeg::FFmpegError("Failed to allocate filter graph");
        }

        // Create audio buffer source
        char ch_layout[64];
        av_channel_layout_describe(&codec_ctx_->ch_layout, ch_layout, sizeof(ch_layout));

        const auto args = std::format(
            "sample_rate={}:sample_fmt={}:channel_layout={}:time_base={}/{}",
            codec_ctx_->sample_rate,
            av_get_sample_fmt_name(codec_ctx_->sample_fmt),
            ch_layout,
            1, codec_ctx_->sample_rate
        );

        ffmpeg::check_error(
            avfilter_graph_create_filter(&buffersrc_ctx_, abuffersrc, "in",
                                        args.c_str(), nullptr, filter_graph_.get()),
            "create audio buffer source"
        );

        // Create video buffer sink
        ffmpeg::check_error(
            avfilter_graph_create_filter(&buffersink_ctx_, buffersink, "out",
                                        nullptr, nullptr, filter_graph_.get()),
            "create buffer sink"
        );

        // Setup filter graph
        const auto filter_desc = get_filter_description(mode_, width_, height_);

        AVFilterInOut* outputs = avfilter_inout_alloc();
        AVFilterInOut* inputs = avfilter_inout_alloc();

        if (!outputs || !inputs) {
            avfilter_inout_free(&inputs);
            avfilter_inout_free(&outputs);
            throw ffmpeg::FFmpegError("Failed to allocate filter I/O");
        }

        outputs->name = av_strdup("in");
        outputs->filter_ctx = buffersrc_ctx_;
        outputs->pad_idx = 0;
        outputs->next = nullptr;

        inputs->name = av_strdup("out");
        inputs->filter_ctx = buffersink_ctx_;
        inputs->pad_idx = 0;
        inputs->next = nullptr;

        const auto ret = avfilter_graph_parse_ptr(filter_graph_.get(), filter_desc.c_str(),
                                                 &inputs, &outputs, nullptr);
        avfilter_inout_free(&inputs);
        avfilter_inout_free(&outputs);

        ffmpeg::check_error(ret, "parse filter graph");

        ffmpeg::check_error(
            avfilter_graph_config(filter_graph_.get(), nullptr),
            "configure filter graph"
        );
    }

    void encode_write_frame(AVFormatContext* output_ctx, AVStream* out_stream, AVFrame* frame) {
        auto encoded_packet = ffmpeg::create_packet();

        const auto ret = avcodec_send_frame(encoder_ctx_.get(), frame);
        if (ret < 0) {
            return;
        }

        while (avcodec_receive_packet(encoder_ctx_.get(), encoded_packet.get()) >= 0) {
            ffmpeg::ScopedPacketUnref packet_guard(encoded_packet.get());

            av_packet_rescale_ts(encoded_packet.get(), encoder_ctx_->time_base,
                               out_stream->time_base);
            encoded_packet->stream_index = out_stream->index;

            ffmpeg::check_error(
                av_interleaved_write_frame(output_ctx, encoded_packet.get()),
                "write frame"
            );
        }
    }

    void flush_encoder(AVFormatContext* output_ctx, AVStream* out_stream) {
        avcodec_send_frame(encoder_ctx_.get(), nullptr);

        auto encoded_packet = ffmpeg::create_packet();
        while (avcodec_receive_packet(encoder_ctx_.get(), encoded_packet.get()) >= 0) {
            ffmpeg::ScopedPacketUnref packet_guard(encoded_packet.get());

            av_packet_rescale_ts(encoded_packet.get(), encoder_ctx_->time_base,
                               out_stream->time_base);
            encoded_packet->stream_index = out_stream->index;

            av_interleaved_write_frame(output_ctx, encoded_packet.get());
        }
    }

    std::string input_audio_;
    fs::path output_video_;
    VisualizationMode mode_;
    int width_;
    int height_;
    int fps_;
    int audio_stream_index_ = -1;

    ffmpeg::FormatContextPtr format_ctx_;
    ffmpeg::CodecContextPtr codec_ctx_;
    ffmpeg::CodecContextPtr encoder_ctx_;
    ffmpeg::FilterGraphPtr filter_graph_;
    ffmpeg::PacketPtr packet_;

    AVFilterContext* buffersrc_ctx_ = nullptr;
    AVFilterContext* buffersink_ctx_ = nullptr;
};

void print_usage(std::string_view prog_name) {
    std::cout << std::format("Usage: {} <input_audio> <output_video> <mode> [width] [height] [fps]\n\n", prog_name);
    std::cout << "Visualization Modes:\n";
    std::cout << "  spectrum    - Frequency spectrum (default)\n";
    std::cout << "  waveform    - Waveform display\n";
    std::cout << "  showcqt     - Constant Q Transform spectrum\n";
    std::cout << "  showfreqs   - Frequency bars\n";
    std::cout << "  showwaves   - Waveform with multiple styles\n\n";
    std::cout << "Parameters:\n";
    std::cout << "  width       - Video width (default: 1280)\n";
    std::cout << "  height      - Video height (default: 720)\n";
    std::cout << "  fps         - Frame rate (default: 30)\n\n";
    std::cout << "Examples:\n";
    std::cout << std::format("  {} music.mp3 spectrum.mp4 spectrum\n", prog_name);
    std::cout << std::format("  {} audio.wav waveform.mp4 waveform 1920 1080 60\n", prog_name);
    std::cout << std::format("  {} song.flac visual.mp4 showcqt 1280 720\n", prog_name);
}

} // anonymous namespace

int main(int argc, char* argv[]) {
    if (argc < 4) {
        print_usage(argv[0]);
        return 1;
    }

    try {
        const std::string_view input_audio{argv[1]};
        const fs::path output_video{argv[2]};
        const auto mode = parse_mode(argv[3]);
        const int width = argc > 4 ? std::atoi(argv[4]) : 1280;
        const int height = argc > 5 ? std::atoi(argv[5]) : 720;
        const int fps = argc > 6 ? std::atoi(argv[6]) : 30;

        AudioSpectrumVisualizer visualizer(input_audio, output_video, mode, width, height, fps);
        visualizer.generate();

    } catch (const ffmpeg::FFmpegError& e) {
        std::cerr << std::format("FFmpeg error: {}\n", e.what());
        return 1;
    } catch (const std::exception& e) {
        std::cerr << std::format("Error: {}\n", e.what());
        return 1;
    }

    return 0;
}
